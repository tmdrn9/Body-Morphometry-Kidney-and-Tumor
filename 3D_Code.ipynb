{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "최종.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2021-09-01T08:35:14.021573Z",
          "iopub.execute_input": "2021-09-01T08:35:14.021886Z",
          "iopub.status.idle": "2021-09-01T08:35:16.346985Z",
          "shell.execute_reply.started": "2021-09-01T08:35:14.021857Z",
          "shell.execute_reply": "2021-09-01T08:35:16.346056Z"
        },
        "trusted": true,
        "id": "0ya1TyASzIyN"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import PIL \n",
        "import urllib\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from random import uniform\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:35:16.348571Z",
          "iopub.execute_input": "2021-09-01T08:35:16.348928Z",
          "iopub.status.idle": "2021-09-01T08:35:16.353582Z",
          "shell.execute_reply.started": "2021-09-01T08:35:16.348891Z",
          "shell.execute_reply": "2021-09-01T08:35:16.352648Z"
        },
        "trusted": true,
        "id": "3utquKdVzIy-"
      },
      "source": [
        "import torch.utils.data as td\n",
        "import torchvision as tv\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:35:16.355539Z",
          "iopub.execute_input": "2021-09-01T08:35:16.355948Z",
          "iopub.status.idle": "2021-09-01T08:35:16.362635Z",
          "shell.execute_reply.started": "2021-09-01T08:35:16.355913Z",
          "shell.execute_reply": "2021-09-01T08:35:16.361831Z"
        },
        "trusted": true,
        "id": "tZNRQwN0zIzZ"
      },
      "source": [
        "import pydicom as dcm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QWDz_n6zIzf"
      },
      "source": [
        "dcm참고\n",
        "\n",
        "* https://m.blog.naver.com/siniphia/221883580711\n",
        "* https://ballentain.tistory.com/53"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:35:16.364138Z",
          "iopub.execute_input": "2021-09-01T08:35:16.364768Z",
          "iopub.status.idle": "2021-09-01T08:35:19.903144Z",
          "shell.execute_reply.started": "2021-09-01T08:35:16.364733Z",
          "shell.execute_reply": "2021-09-01T08:35:19.902264Z"
        },
        "trusted": true,
        "id": "VA8Ii3sszI0p"
      },
      "source": [
        "import glob\n",
        "data_path=sorted(glob.glob( \"../input/body-morphometry-kidney-and-tumor/train/DICOM/**/*.dcm\",recursive=True ))\n",
        "label_path=sorted(glob.glob(\"../input/body-morphometry-kidney-and-tumor/train/Label/**/*.png\",recursive = True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:35:19.905220Z",
          "iopub.execute_input": "2021-09-01T08:35:19.905565Z",
          "iopub.status.idle": "2021-09-01T08:35:19.913138Z",
          "shell.execute_reply.started": "2021-09-01T08:35:19.905530Z",
          "shell.execute_reply": "2021-09-01T08:35:19.912345Z"
        },
        "trusted": true,
        "id": "wTzIlCoYzI0s"
      },
      "source": [
        "os.mkdir('./input_data')\n",
        "os.mkdir('./input_label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:35:19.916787Z",
          "iopub.execute_input": "2021-09-01T08:35:19.917067Z",
          "iopub.status.idle": "2021-09-01T08:36:42.069634Z",
          "shell.execute_reply.started": "2021-09-01T08:35:19.917037Z",
          "shell.execute_reply": "2021-09-01T08:36:42.068763Z"
        },
        "trusted": true,
        "id": "JheMyKzezI0-",
        "outputId": "344235fb-03d0-4f37-af38-a4563c202c24"
      },
      "source": [
        "from skimage.io import imread\n",
        "cnt=0\n",
        "size=32\n",
        "na =0\n",
        "\n",
        "for c in tqdm(range(100)):\n",
        "    \n",
        "    for k in range(int(64/size)):\n",
        "        input_d=[]\n",
        "        label_d=[]\n",
        "        input_p = data_path[cnt:cnt+size]\n",
        "        label_p = label_path[cnt:cnt+size]\n",
        "        \n",
        "        for i in range(size):\n",
        "            read = dcm.read_file(input_p[i])\n",
        "            input_d.append(read)\n",
        "\n",
        "            y_img=imread(label_p[i])\n",
        "            label_d.append(y_img)\n",
        "\n",
        "        np.save(f'./input_data/train_0{na}', input_d)\n",
        "        np.save(f'./input_label/label_0{na}', label_d)\n",
        "        na+=1\n",
        "         \n",
        "    \n",
        "    cnt = cnt+size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "100%|██████████| 100/100 [01:22<00:00,  1.22it/s]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:42.071190Z",
          "iopub.execute_input": "2021-09-01T08:36:42.071682Z",
          "iopub.status.idle": "2021-09-01T08:36:42.079656Z",
          "shell.execute_reply.started": "2021-09-01T08:36:42.071643Z",
          "shell.execute_reply": "2021-09-01T08:36:42.078708Z"
        },
        "trusted": true,
        "id": "mEpUMaY-zI1j"
      },
      "source": [
        "import glob\n",
        "data_path=sorted(glob.glob( \"./input_data/*.npy\" ))\n",
        "label_path=sorted(glob.glob(\"./input_label/*.npy\",recursive = True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:42.081052Z",
          "iopub.execute_input": "2021-09-01T08:36:42.081629Z",
          "iopub.status.idle": "2021-09-01T08:36:42.089947Z",
          "shell.execute_reply.started": "2021-09-01T08:36:42.081585Z",
          "shell.execute_reply": "2021-09-01T08:36:42.088898Z"
        },
        "trusted": true,
        "id": "dp2lr3DuzI1r",
        "outputId": "117f006b-2d12-4637-bcc3-21311e77a9ac"
      },
      "source": [
        "len(data_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "200"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:42.091452Z",
          "iopub.execute_input": "2021-09-01T08:36:42.091830Z",
          "iopub.status.idle": "2021-09-01T08:36:42.104725Z",
          "shell.execute_reply.started": "2021-09-01T08:36:42.091793Z",
          "shell.execute_reply": "2021-09-01T08:36:42.103958Z"
        },
        "trusted": true,
        "id": "rC3knKs5zI1x"
      },
      "source": [
        "from skimage.transform import resize\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "import numpy as np\n",
        "import pydicom\n",
        "\n",
        "def transform_to_hu(medical_image, image):\n",
        "    hu_image = image *1 + 0\n",
        "    hu_image[hu_image < -1024] = -1024\n",
        "    return hu_image\n",
        "\n",
        "def window_image(image, window_center, window_width):\n",
        "    window_image = image.copy()\n",
        "    image_min = window_center - (window_width / 2)\n",
        "    image_max = window_center + (window_width / 2)\n",
        "    window_image[window_image < image_min] = image_min\n",
        "    window_image[window_image > image_max] = image_max\n",
        "    return window_image\n",
        "\n",
        "def resize_normalize(image):\n",
        "    image = np.array(image, dtype=np.float32)\n",
        "    image -= np.min(image)\n",
        "    image /= np.max(image)\n",
        "    return image\n",
        "\n",
        "def read_dicom(image_medical, window_widht, window_level):\n",
        "    img3d_input = np.zeros([512,512,1,32])\n",
        "    for i in range(32):\n",
        "        image_data = image_medical[i].pixel_array\n",
        "\n",
        "        image_hu = transform_to_hu(image_medical, image_data)\n",
        "        image_window = window_image(image_hu.copy(), window_level, window_widht)\n",
        "        image_window_norm = resize_normalize(image_window)\n",
        "        #     image_window_norm = image_window\n",
        "\n",
        "        image_window_norm = np.expand_dims(image_window_norm, axis=2)   # (512, 512, 1)\n",
        "#         image_ths = np.concatenate([image_window_norm, image_window_norm, image_window_norm], axis=2)   # (512, 512, 3)\n",
        "        img3d_input[:, :,:,i] = image_window_norm\n",
        "#         img3d_input[:, :,:,i] = image_ths\n",
        "\n",
        "    return img3d_input\n",
        "\n",
        "def to_binary(img, lower, upper):\n",
        "    return (lower <= img) & (img <= upper)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:42.107559Z",
          "iopub.execute_input": "2021-09-01T08:36:42.107818Z",
          "iopub.status.idle": "2021-09-01T08:36:42.118429Z",
          "shell.execute_reply.started": "2021-09-01T08:36:42.107787Z",
          "shell.execute_reply": "2021-09-01T08:36:42.117418Z"
        },
        "trusted": true,
        "id": "Rf71gNkDzI11"
      },
      "source": [
        "def mask_binarization(mask, threshold=None):\n",
        "    if threshold is None:\n",
        "        threshold = 0.5\n",
        "\n",
        "    if isinstance(mask, np.ndarray):\n",
        "        mask_binarized = (mask > threshold).astype(np.uint8)\n",
        "    \n",
        "    elif isinstance(mask, torch.Tensor):\n",
        "        zeros = torch.zeros_like(mask)\n",
        "        ones = torch.ones_like(mask)\n",
        "        \n",
        "        mask_binarized = torch.where(mask > threshold, ones, zeros)\n",
        "    \n",
        "    return mask_binarized\n",
        "\n",
        "def augment_imgs_and_masks(imgs, masks, rot_factor, scale_factor, trans_factor, flip):\n",
        "    rot_factor = uniform(-rot_factor, rot_factor)\n",
        "    ran_alp = uniform(10,100)\n",
        "    scale_factor = uniform(1-scale_factor, 1+scale_factor)\n",
        "    trans_factor = [int(imgs.shape[1]*uniform(-trans_factor, trans_factor)),\n",
        "                    int(imgs.shape[2]*uniform(-trans_factor, trans_factor))]\n",
        "\n",
        "    seq = iaa.Sequential([\n",
        "            iaa.Affine(\n",
        "                translate_px={\"x\": trans_factor[0], \"y\": trans_factor[1]},\n",
        "                scale=(scale_factor, scale_factor),\n",
        "                rotate=rot_factor\n",
        "            ),\n",
        "            iaa.ElasticTransformation(alpha=ran_alp,sigma=5.0)\n",
        "        \n",
        "        ])\n",
        "\n",
        "    seq_det = seq.to_deterministic()\n",
        "\n",
        "    imgs = seq_det.augment_images(imgs)\n",
        "    masks = seq_det.augment_images(masks)\n",
        "\n",
        "    if flip and uniform(0, 1) > 0.5:\n",
        "        imgs = np.flip(imgs, 2).copy()\n",
        "        masks = np.flip(masks, 2).copy()\n",
        "    \n",
        "    masks = mask_binarization(masks).astype(np.float32)\n",
        "    return imgs, masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:42.121699Z",
          "iopub.execute_input": "2021-09-01T08:36:42.122266Z",
          "iopub.status.idle": "2021-09-01T08:36:42.132596Z",
          "shell.execute_reply.started": "2021-09-01T08:36:42.122230Z",
          "shell.execute_reply": "2021-09-01T08:36:42.131743Z"
        },
        "trusted": true,
        "id": "zSPQn1m7zI13"
      },
      "source": [
        "# Data augmentation\n",
        "rot_factor = 30. \n",
        "scale_factor = 0.15\n",
        "flip = True\n",
        "trans_factor = 0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:42.134528Z",
          "iopub.execute_input": "2021-09-01T08:36:42.134887Z",
          "iopub.status.idle": "2021-09-01T08:36:42.145964Z",
          "shell.execute_reply.started": "2021-09-01T08:36:42.134854Z",
          "shell.execute_reply": "2021-09-01T08:36:42.145186Z"
        },
        "trusted": true,
        "id": "AmIx3fkRzI2C"
      },
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_dir, y_dir, augmentation=True):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        self.augmentation = augmentation\n",
        "#         self.transform = transforms\n",
        "        self.x_img = x_dir\n",
        "        self.y_img = y_dir   \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_img)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_img = self.x_img[idx]\n",
        "        y_img = self.y_img[idx]\n",
        "        x_img = np.load(x_img, allow_pickle=True)\n",
        "        y_img = np.load(y_img, allow_pickle=True)\n",
        "\n",
        "        x_img=read_dicom(x_img,500,0)\n",
        "        x_img=np.transpose(x_img,(2,0,1,3))\n",
        "        \n",
        "#         y_img = np.expand_dims(y_img, axis=3)\n",
        "#         y_img=np.transpose(y_img,(3,1,2,0))\n",
        "        # (512, 512, 1)\n",
        "        color_im = np.zeros([32,512, 512,2])\n",
        "        for i in range(1,3):\n",
        "            encode_ = to_binary(y_img, i*1.0, i*1.0) * 255\n",
        "            color_im[:, :,:,i-1] = encode_\n",
        "        color_im = np.transpose(color_im,(3,1,2,0))\n",
        "        \n",
        "        \n",
        "        # Data Augmentation\n",
        "        if self.augmentation:\n",
        "            img, mask = augment_imgs_and_masks(x_img,color_im, rot_factor, scale_factor, trans_factor, flip)\n",
        "\n",
        "#             augmented = self.transforms(image=x_img,mask=color_im)\n",
        "#             img = augmented['image']\n",
        "#             mask = augmented['mask']\n",
        "            \n",
        "            \n",
        "            return img, mask\n",
        "\n",
        "        # return x_img,color_im,y_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:42.147205Z",
          "iopub.execute_input": "2021-09-01T08:36:42.147746Z",
          "iopub.status.idle": "2021-09-01T08:36:42.159239Z",
          "shell.execute_reply.started": "2021-09-01T08:36:42.147684Z",
          "shell.execute_reply": "2021-09-01T08:36:42.158452Z"
        },
        "trusted": true,
        "id": "lApawT12zI2H",
        "outputId": "22ec63e4-2329-4f44-dd49-6b0f59e58d7b"
      },
      "source": [
        "len(data_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 19,
          "output_type": "execute_result",
          "data": {
            "text/plain": "200"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:42.160228Z",
          "iopub.execute_input": "2021-09-01T08:36:42.160498Z",
          "iopub.status.idle": "2021-09-01T08:36:42.169519Z",
          "shell.execute_reply.started": "2021-09-01T08:36:42.160475Z",
          "shell.execute_reply": "2021-09-01T08:36:42.168765Z"
        },
        "trusted": true,
        "id": "sevxddgozI2J"
      },
      "source": [
        "import pandas as pd\n",
        "data_path = pd.array(data_path)\n",
        "label_path = pd.array(label_path)\n",
        "\n",
        "train_input_files = data_path[40:].to_numpy()\n",
        "train_label_files = label_path[40:].to_numpy()\n",
        "\n",
        "val_input_files = data_path[:40].to_numpy()\n",
        "val_label_files = label_path[:40].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:42.170771Z",
          "iopub.execute_input": "2021-09-01T08:36:42.171123Z",
          "iopub.status.idle": "2021-09-01T08:36:42.178142Z",
          "shell.execute_reply.started": "2021-09-01T08:36:42.171076Z",
          "shell.execute_reply": "2021-09-01T08:36:42.177381Z"
        },
        "trusted": true,
        "id": "_vOHxZTQzI2M"
      },
      "source": [
        "train_dataset = MyDataset(train_input_files,train_label_files)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=1,shuffle=True)\n",
        "val_dataset = MyDataset(val_input_files,val_label_files)\n",
        "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:42.179577Z",
          "iopub.execute_input": "2021-09-01T08:36:42.180010Z",
          "iopub.status.idle": "2021-09-01T08:36:44.630791Z",
          "shell.execute_reply.started": "2021-09-01T08:36:42.179975Z",
          "shell.execute_reply": "2021-09-01T08:36:44.629864Z"
        },
        "trusted": true,
        "id": "5s_FOSKLzI2O",
        "outputId": "fc1b896c-96e1-46e7-9b82-bdd325378ae5"
      },
      "source": [
        "images,mask = next(iter(train_loader))\n",
        "print(images.shape)\n",
        "print(mask.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "torch.Size([1, 1, 512, 512, 32])\ntorch.Size([1, 2, 512, 512, 32])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:44.632161Z",
          "iopub.execute_input": "2021-09-01T08:36:44.632500Z",
          "iopub.status.idle": "2021-09-01T08:36:44.671749Z",
          "shell.execute_reply.started": "2021-09-01T08:36:44.632464Z",
          "shell.execute_reply": "2021-09-01T08:36:44.670961Z"
        },
        "trusted": true,
        "id": "j3qdEnIVzI2Q"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class Modified3DUNet(nn.Module):\n",
        "\tdef __init__(self, in_channels, n_classes, base_n_filter = 8):\n",
        "\t\tsuper(Modified3DUNet, self).__init__()\n",
        "\t\tself.in_channels = in_channels\n",
        "\t\tself.n_classes = n_classes\n",
        "\t\tself.base_n_filter = base_n_filter\n",
        "\n",
        "\t\tself.lrelu = nn.LeakyReLU()\n",
        "\t\tself.dropout3d = nn.Dropout3d(p=0.6)\n",
        "\t\tself.upsacle = nn.Upsample(scale_factor=2, mode='nearest')\n",
        "\t\tself.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "\t\t# Level 1 context pathway\n",
        "\t\tself.conv3d_c1_1 = nn.Conv3d(self.in_channels, self.base_n_filter, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\t\tself.conv3d_c1_2 = nn.Conv3d(self.base_n_filter, self.base_n_filter, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "\t\tself.lrelu_conv_c1 = self.lrelu_conv(self.base_n_filter, self.base_n_filter)\n",
        "\t\tself.inorm3d_c1 = nn.InstanceNorm3d(self.base_n_filter)\n",
        "\n",
        "\t\t# Level 2 context pathway\n",
        "\t\tself.conv3d_c2 = nn.Conv3d(self.base_n_filter, self.base_n_filter*2, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\t\tself.norm_lrelu_conv_c2 = self.norm_lrelu_conv(self.base_n_filter*2, self.base_n_filter*2)\n",
        "\t\tself.inorm3d_c2 = nn.InstanceNorm3d(self.base_n_filter*2)\n",
        "\n",
        "\t\t# Level 3 context pathway\n",
        "\t\tself.conv3d_c3 = nn.Conv3d(self.base_n_filter*2, self.base_n_filter*4, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\t\tself.norm_lrelu_conv_c3 = self.norm_lrelu_conv(self.base_n_filter*4, self.base_n_filter*4)\n",
        "\t\tself.inorm3d_c3 = nn.InstanceNorm3d(self.base_n_filter*4)\n",
        "\n",
        "\t\t# Level 4 context pathway\n",
        "\t\tself.conv3d_c4 = nn.Conv3d(self.base_n_filter*4, self.base_n_filter*8, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\t\tself.norm_lrelu_conv_c4 = self.norm_lrelu_conv(self.base_n_filter*8, self.base_n_filter*8)\n",
        "\t\tself.inorm3d_c4 = nn.InstanceNorm3d(self.base_n_filter*8)\n",
        "\n",
        "\t\t# Level 5 context pathway, level 0 localization pathway\n",
        "\t\tself.conv3d_c5 = nn.Conv3d(self.base_n_filter*8, self.base_n_filter*16, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "\t\tself.norm_lrelu_conv_c5 = self.norm_lrelu_conv(self.base_n_filter*16, self.base_n_filter*16)\n",
        "\t\tself.norm_lrelu_upscale_conv_norm_lrelu_l0 = self.norm_lrelu_upscale_conv_norm_lrelu(self.base_n_filter*16, self.base_n_filter*8)\n",
        "\n",
        "\t\tself.conv3d_l0 = nn.Conv3d(self.base_n_filter*8, self.base_n_filter*8, kernel_size = 1, stride=1, padding=0, bias=False)\n",
        "\t\tself.inorm3d_l0 = nn.InstanceNorm3d(self.base_n_filter*8)\n",
        "\n",
        "\t\t# Level 1 localization pathway\n",
        "\t\tself.conv_norm_lrelu_l1 = self.conv_norm_lrelu(self.base_n_filter*16, self.base_n_filter*16)\n",
        "\t\tself.conv3d_l1 = nn.Conv3d(self.base_n_filter*16, self.base_n_filter*8, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "\t\tself.norm_lrelu_upscale_conv_norm_lrelu_l1 = self.norm_lrelu_upscale_conv_norm_lrelu(self.base_n_filter*8, self.base_n_filter*4)\n",
        "\n",
        "\t\t# Level 2 localization pathway\n",
        "\t\tself.conv_norm_lrelu_l2 = self.conv_norm_lrelu(self.base_n_filter*8, self.base_n_filter*8)\n",
        "\t\tself.conv3d_l2 = nn.Conv3d(self.base_n_filter*8, self.base_n_filter*4, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "\t\tself.norm_lrelu_upscale_conv_norm_lrelu_l2 = self.norm_lrelu_upscale_conv_norm_lrelu(self.base_n_filter*4, self.base_n_filter*2)\n",
        "\n",
        "\t\t# Level 3 localization pathway\n",
        "\t\tself.conv_norm_lrelu_l3 = self.conv_norm_lrelu(self.base_n_filter*4, self.base_n_filter*4)\n",
        "\t\tself.conv3d_l3 = nn.Conv3d(self.base_n_filter*4, self.base_n_filter*2, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "\t\tself.norm_lrelu_upscale_conv_norm_lrelu_l3 = self.norm_lrelu_upscale_conv_norm_lrelu(self.base_n_filter*2, self.base_n_filter)\n",
        "\n",
        "\t\t# Level 4 localization pathway\n",
        "\t\tself.conv_norm_lrelu_l4 = self.conv_norm_lrelu(self.base_n_filter*2, self.base_n_filter*2)\n",
        "\t\tself.conv3d_l4 = nn.Conv3d(self.base_n_filter*2, self.n_classes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "\n",
        "\t\tself.ds2_1x1_conv3d = nn.Conv3d(self.base_n_filter*8, self.n_classes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "\t\tself.ds3_1x1_conv3d = nn.Conv3d(self.base_n_filter*4, self.n_classes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\tdef conv_norm_lrelu(self, feat_in, feat_out):\n",
        "\t\treturn nn.Sequential(\n",
        "\t\t\tnn.Conv3d(feat_in, feat_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "\t\t\tnn.InstanceNorm3d(feat_out),\n",
        "\t\t\tnn.LeakyReLU())\n",
        "\n",
        "\tdef norm_lrelu_conv(self, feat_in, feat_out):\n",
        "\t\treturn nn.Sequential(\n",
        "\t\t\tnn.InstanceNorm3d(feat_in),\n",
        "\t\t\tnn.LeakyReLU(),\n",
        "\t\t\tnn.Conv3d(feat_in, feat_out, kernel_size=3, stride=1, padding=1, bias=False))\n",
        "\n",
        "\tdef lrelu_conv(self, feat_in, feat_out):\n",
        "\t\treturn nn.Sequential(\n",
        "\t\t\tnn.LeakyReLU(),\n",
        "\t\t\tnn.Conv3d(feat_in, feat_out, kernel_size=3, stride=1, padding=1, bias=False))\n",
        "\n",
        "\tdef norm_lrelu_upscale_conv_norm_lrelu(self, feat_in, feat_out):\n",
        "\t\treturn nn.Sequential(\n",
        "\t\t\tnn.InstanceNorm3d(feat_in),\n",
        "\t\t\tnn.LeakyReLU(),\n",
        "\t\t\tnn.Upsample(scale_factor=2, mode='nearest'),\n",
        "\t\t\t# should be feat_in*2 or feat_in\n",
        "\t\t\tnn.Conv3d(feat_in, feat_out, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "\t\t\tnn.InstanceNorm3d(feat_out),\n",
        "\t\t\tnn.LeakyReLU())\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t#  Level 1 context pathway\n",
        "\t\tout = self.conv3d_c1_1(x)\n",
        "\t\tresidual_1 = out\n",
        "\t\tout = self.lrelu(out)\n",
        "\t\tout = self.conv3d_c1_2(out)\n",
        "\t\tout = self.dropout3d(out)\n",
        "\t\tout = self.lrelu_conv_c1(out)\n",
        "\t\t# Element Wise Summation\n",
        "\t\tout += residual_1\n",
        "\t\tcontext_1 = self.lrelu(out)\n",
        "\t\tout = self.inorm3d_c1(out)\n",
        "\t\tout = self.lrelu(out)\n",
        "\n",
        "\t\t# Level 2 context pathway\n",
        "\t\tout = self.conv3d_c2(out)\n",
        "\t\tresidual_2 = out\n",
        "\t\tout = self.norm_lrelu_conv_c2(out)\n",
        "\t\tout = self.dropout3d(out)\n",
        "\t\tout = self.norm_lrelu_conv_c2(out)\n",
        "\t\tout += residual_2\n",
        "\t\tout = self.inorm3d_c2(out)\n",
        "\t\tout = self.lrelu(out)\n",
        "\t\tcontext_2 = out\n",
        "\n",
        "\t\t# Level 3 context pathway\n",
        "\t\tout = self.conv3d_c3(out)\n",
        "\t\tresidual_3 = out\n",
        "\t\tout = self.norm_lrelu_conv_c3(out)\n",
        "\t\tout = self.dropout3d(out)\n",
        "\t\tout = self.norm_lrelu_conv_c3(out)\n",
        "\t\tout += residual_3\n",
        "\t\tout = self.inorm3d_c3(out)\n",
        "\t\tout = self.lrelu(out)\n",
        "\t\tcontext_3 = out\n",
        "\n",
        "\t\t# Level 4 context pathway\n",
        "\t\tout = self.conv3d_c4(out)\n",
        "\t\tresidual_4 = out\n",
        "\t\tout = self.norm_lrelu_conv_c4(out)\n",
        "\t\tout = self.dropout3d(out)\n",
        "\t\tout = self.norm_lrelu_conv_c4(out)\n",
        "\t\tout += residual_4\n",
        "\t\tout = self.inorm3d_c4(out)\n",
        "\t\tout = self.lrelu(out)\n",
        "\t\tcontext_4 = out\n",
        "\n",
        "\t\t# Level 5\n",
        "\t\tout = self.conv3d_c5(out)\n",
        "\t\tresidual_5 = out\n",
        "\t\tout = self.norm_lrelu_conv_c5(out)\n",
        "\t\tout = self.dropout3d(out)\n",
        "\t\tout = self.norm_lrelu_conv_c5(out)\n",
        "\t\tout += residual_5\n",
        "\t\tout = self.norm_lrelu_upscale_conv_norm_lrelu_l0(out)\n",
        "\n",
        "\t\tout = self.conv3d_l0(out)\n",
        "\t\tout = self.inorm3d_l0(out)\n",
        "\t\tout = self.lrelu(out)\n",
        "\n",
        "\t\t# Level 1 localization pathway\n",
        "\t\tout = torch.cat([out, context_4], dim=1)\n",
        "\t\tout = self.conv_norm_lrelu_l1(out)\n",
        "\t\tout = self.conv3d_l1(out)\n",
        "\t\tout = self.norm_lrelu_upscale_conv_norm_lrelu_l1(out)\n",
        "\n",
        "\t\t# Level 2 localization pathway\n",
        "\t\tout = torch.cat([out, context_3], dim=1)\n",
        "\t\tout = self.conv_norm_lrelu_l2(out)\n",
        "\t\tds2 = out\n",
        "\t\tout = self.conv3d_l2(out)\n",
        "\t\tout = self.norm_lrelu_upscale_conv_norm_lrelu_l2(out)\n",
        "\n",
        "\t\t# Level 3 localization pathway\n",
        "\t\tout = torch.cat([out, context_2], dim=1)\n",
        "\t\tout = self.conv_norm_lrelu_l3(out)\n",
        "\t\tds3 = out\n",
        "\t\tout = self.conv3d_l3(out)\n",
        "\t\tout = self.norm_lrelu_upscale_conv_norm_lrelu_l3(out)\n",
        "\n",
        "\t\t# Level 4 localization pathway\n",
        "\t\tout = torch.cat([out, context_1], dim=1)\n",
        "\t\tout = self.conv_norm_lrelu_l4(out)\n",
        "\t\tout_pred = self.conv3d_l4(out)\n",
        "\n",
        "\t\tds2_1x1_conv = self.ds2_1x1_conv3d(ds2)\n",
        "\t\tds1_ds2_sum_upscale = self.upsacle(ds2_1x1_conv)\n",
        "\t\tds3_1x1_conv = self.ds3_1x1_conv3d(ds3)\n",
        "\t\tds1_ds2_sum_upscale_ds3_sum = ds1_ds2_sum_upscale + ds3_1x1_conv\n",
        "\t\tds1_ds2_sum_upscale_ds3_sum_upscale = self.upsacle(ds1_ds2_sum_upscale_ds3_sum)\n",
        "\n",
        "\t\tout = out_pred + ds1_ds2_sum_upscale_ds3_sum_upscale\n",
        "\t\tseg_layer = out\n",
        "\t\tout = out.permute(0, 2, 3, 4, 1).contiguous().view(-1, self.n_classes)\n",
        "\t\t#out = out.view(-1, self.n_classes)\n",
        "\t\tout = self.softmax(out)\n",
        "\t\treturn seg_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:44.673097Z",
          "iopub.execute_input": "2021-09-01T08:36:44.673495Z",
          "iopub.status.idle": "2021-09-01T08:36:44.721388Z",
          "shell.execute_reply.started": "2021-09-01T08:36:44.673434Z",
          "shell.execute_reply": "2021-09-01T08:36:44.720662Z"
        },
        "trusted": true,
        "id": "EyQ0QcL8zI2a"
      },
      "source": [
        "model=Modified3DUNet(1,2,13)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:44.722529Z",
          "iopub.execute_input": "2021-09-01T08:36:44.722909Z",
          "iopub.status.idle": "2021-09-01T08:36:44.729378Z",
          "shell.execute_reply.started": "2021-09-01T08:36:44.722873Z",
          "shell.execute_reply": "2021-09-01T08:36:44.728530Z"
        },
        "trusted": true,
        "id": "C-_40jukzI2f",
        "outputId": "76e47fdc-ed06-4a15-dd38-f0a7e5fd6360"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Modified3DUNet(\n  (lrelu): LeakyReLU(negative_slope=0.01)\n  (dropout3d): Dropout3d(p=0.6, inplace=False)\n  (upsacle): Upsample(scale_factor=2.0, mode=nearest)\n  (softmax): Softmax(dim=1)\n  (conv3d_c1_1): Conv3d(1, 13, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n  (conv3d_c1_2): Conv3d(13, 13, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n  (lrelu_conv_c1): Sequential(\n    (0): LeakyReLU(negative_slope=0.01)\n    (1): Conv3d(13, 13, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n  )\n  (inorm3d_c1): InstanceNorm3d(13, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n  (conv3d_c2): Conv3d(13, 26, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n  (norm_lrelu_conv_c2): Sequential(\n    (0): InstanceNorm3d(26, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Conv3d(26, 26, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n  )\n  (inorm3d_c2): InstanceNorm3d(26, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n  (conv3d_c3): Conv3d(26, 52, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n  (norm_lrelu_conv_c3): Sequential(\n    (0): InstanceNorm3d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Conv3d(52, 52, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n  )\n  (inorm3d_c3): InstanceNorm3d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n  (conv3d_c4): Conv3d(52, 104, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n  (norm_lrelu_conv_c4): Sequential(\n    (0): InstanceNorm3d(104, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Conv3d(104, 104, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n  )\n  (inorm3d_c4): InstanceNorm3d(104, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n  (conv3d_c5): Conv3d(104, 208, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n  (norm_lrelu_conv_c5): Sequential(\n    (0): InstanceNorm3d(208, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Conv3d(208, 208, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n  )\n  (norm_lrelu_upscale_conv_norm_lrelu_l0): Sequential(\n    (0): InstanceNorm3d(208, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Upsample(scale_factor=2.0, mode=nearest)\n    (3): Conv3d(208, 104, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n    (4): InstanceNorm3d(104, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (5): LeakyReLU(negative_slope=0.01)\n  )\n  (conv3d_l0): Conv3d(104, 104, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n  (inorm3d_l0): InstanceNorm3d(104, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n  (conv_norm_lrelu_l1): Sequential(\n    (0): Conv3d(208, 208, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n    (1): InstanceNorm3d(208, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (2): LeakyReLU(negative_slope=0.01)\n  )\n  (conv3d_l1): Conv3d(208, 104, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n  (norm_lrelu_upscale_conv_norm_lrelu_l1): Sequential(\n    (0): InstanceNorm3d(104, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Upsample(scale_factor=2.0, mode=nearest)\n    (3): Conv3d(104, 52, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n    (4): InstanceNorm3d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (5): LeakyReLU(negative_slope=0.01)\n  )\n  (conv_norm_lrelu_l2): Sequential(\n    (0): Conv3d(104, 104, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n    (1): InstanceNorm3d(104, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (2): LeakyReLU(negative_slope=0.01)\n  )\n  (conv3d_l2): Conv3d(104, 52, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n  (norm_lrelu_upscale_conv_norm_lrelu_l2): Sequential(\n    (0): InstanceNorm3d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Upsample(scale_factor=2.0, mode=nearest)\n    (3): Conv3d(52, 26, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n    (4): InstanceNorm3d(26, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (5): LeakyReLU(negative_slope=0.01)\n  )\n  (conv_norm_lrelu_l3): Sequential(\n    (0): Conv3d(52, 52, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n    (1): InstanceNorm3d(52, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (2): LeakyReLU(negative_slope=0.01)\n  )\n  (conv3d_l3): Conv3d(52, 26, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n  (norm_lrelu_upscale_conv_norm_lrelu_l3): Sequential(\n    (0): InstanceNorm3d(26, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Upsample(scale_factor=2.0, mode=nearest)\n    (3): Conv3d(26, 13, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n    (4): InstanceNorm3d(13, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (5): LeakyReLU(negative_slope=0.01)\n  )\n  (conv_norm_lrelu_l4): Sequential(\n    (0): Conv3d(26, 26, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n    (1): InstanceNorm3d(26, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n    (2): LeakyReLU(negative_slope=0.01)\n  )\n  (conv3d_l4): Conv3d(26, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n  (ds2_1x1_conv3d): Conv3d(104, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n  (ds3_1x1_conv3d): Conv3d(52, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:44.730814Z",
          "iopub.execute_input": "2021-09-01T08:36:44.731487Z",
          "iopub.status.idle": "2021-09-01T08:36:44.793670Z",
          "shell.execute_reply.started": "2021-09-01T08:36:44.731450Z",
          "shell.execute_reply": "2021-09-01T08:36:44.792915Z"
        },
        "trusted": true,
        "id": "FxC1joWvzI2h",
        "outputId": "a8c2a4d3-f708-46ba-fe3f-567abcf45a83"
      },
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "    \n",
        "device"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'cuda'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:44.794905Z",
          "iopub.execute_input": "2021-09-01T08:36:44.795363Z",
          "iopub.status.idle": "2021-09-01T08:36:44.805929Z",
          "shell.execute_reply.started": "2021-09-01T08:36:44.795249Z",
          "shell.execute_reply": "2021-09-01T08:36:44.804747Z"
        },
        "trusted": true,
        "id": "BzSRgjt-zI2j"
      },
      "source": [
        "import importlib\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "\n",
        "plt.ioff()\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "def expand_as_one_hot(input, C, ignore_index=None):\n",
        "    \"\"\"\n",
        "    Converts NxSPATIAL label image to NxCxSPATIAL, where each label gets converted to its corresponding one-hot vector.\n",
        "    It is assumed that the batch dimension is present.\n",
        "    Args:\n",
        "        input (torch.Tensor): 3D/4D input image\n",
        "        C (int): number of channels/labels\n",
        "        ignore_index (int): ignore index to be kept during the expansion\n",
        "    Returns:\n",
        "        4D/5D output torch.Tensor (NxCxSPATIAL)\n",
        "    \"\"\"\n",
        "    assert input.dim() == 4\n",
        "\n",
        "    # expand the input tensor to Nx1xSPATIAL before scattering\n",
        "    input = input.unsqueeze(1)\n",
        "    # create output tensor shape (NxCxSPATIAL)\n",
        "    shape = list(input.size())\n",
        "    shape[1] = C\n",
        "\n",
        "    if ignore_index is not None:\n",
        "        # create ignore_index mask for the result\n",
        "        mask = input.expand(shape) == ignore_index\n",
        "        # clone the src tensor and zero out ignore_index in the input\n",
        "        input = input.clone()\n",
        "        input[input == ignore_index] = 0\n",
        "        # scatter to get the one-hot tensor\n",
        "        result = torch.zeros(shape).to(input.device).scatter_(1, input, 1)\n",
        "        # bring back the ignore_index in the result\n",
        "        result[mask] = ignore_index\n",
        "        return result\n",
        "    else:\n",
        "        # scatter to get the one-hot tensor\n",
        "        return torch.zeros(shape).to(input.device).scatter_(1, input, 1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:44.807809Z",
          "iopub.execute_input": "2021-09-01T08:36:44.808504Z",
          "iopub.status.idle": "2021-09-01T08:36:44.829754Z",
          "shell.execute_reply.started": "2021-09-01T08:36:44.808468Z",
          "shell.execute_reply": "2021-09-01T08:36:44.828968Z"
        },
        "trusted": true,
        "id": "N8SqCPG4zI2k"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import MSELoss, SmoothL1Loss, L1Loss\n",
        "\n",
        "\n",
        "def flatten(tensor):\n",
        "    \"\"\"Flattens a given tensor such that the channel axis is first.\n",
        "    The shapes are transformed as follows:\n",
        "       (N, C, D, H, W) -> (C, N * D * H * W)\n",
        "    \"\"\"\n",
        "    # number of channels\n",
        "    C = tensor.size(1)\n",
        "    # new axis order\n",
        "    axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n",
        "    # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n",
        "    transposed = tensor.permute(axis_order)\n",
        "    # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n",
        "    return transposed.contiguous().view(C, -1)\n",
        "    #1,2,512,512,64 N,C,H,W,D\n",
        "    #\n",
        "\n",
        "def compute_per_channel_dice(input, target, epsilon=1e-6, weight=None):\n",
        "    \"\"\"\n",
        "    Computes DiceCoefficient as defined in https://arxiv.org/abs/1606.04797 given  a multi channel input and target.\n",
        "    Assumes the input is a normalized probability, e.g. a result of Sigmoid or Softmax function.\n",
        "    Args:\n",
        "         input (torch.Tensor): NxCxSpatial input tensor\n",
        "         target (torch.Tensor): NxCxSpatial target tensor\n",
        "         epsilon (float): prevents division by zero\n",
        "         weight (torch.Tensor): Cx1 tensor of weight per channel/class\n",
        "    \"\"\"\n",
        "\n",
        "    # input and target shapes must match\n",
        "    assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
        "    input=input.permute(0,1,4,2,3).contiguous()\n",
        "    target=target.permute(0,1,4,2,3).contiguous()\n",
        "    input = flatten(input)\n",
        "    target = flatten(target)\n",
        "    target = target.float()\n",
        "\n",
        "    # compute per channel Dice Coefficient\n",
        "    intersect = (input * target).sum(-1)\n",
        "    if weight is not None:\n",
        "        intersect = weight * intersect\n",
        "\n",
        "    # here we can use standard dice (input + target).sum(-1) or extension (see V-Net) (input^2 + target^2).sum(-1)\n",
        "    denominator = (input * input).sum(-1) + (target * target).sum(-1)\n",
        "    return 2 * (intersect / denominator.clamp(min=epsilon))\n",
        "\n",
        "\n",
        "class _MaskingLossWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Loss wrapper which prevents the gradient of the loss to be computed where target is equal to `ignore_index`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, loss, ignore_index):\n",
        "        super(_MaskingLossWrapper, self).__init__()\n",
        "        assert ignore_index is not None, 'ignore_index cannot be None'\n",
        "        self.loss = loss\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        mask = target.clone().ne_(self.ignore_index)\n",
        "        mask.requires_grad = False\n",
        "\n",
        "        # mask out input/target so that the gradient is zero where on the mask\n",
        "        input = input * mask\n",
        "        target = target * mask\n",
        "\n",
        "        # forward masked input and target to the loss\n",
        "        return self.loss(input, target)\n",
        "\n",
        "\n",
        "class SkipLastTargetChannelWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Loss wrapper which removes additional target channel\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, loss, squeeze_channel=False):\n",
        "        super(SkipLastTargetChannelWrapper, self).__init__()\n",
        "        self.loss = loss\n",
        "        self.squeeze_channel = squeeze_channel\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        assert target.size(1) > 1, 'Target tensor has a singleton channel dimension, cannot remove channel'\n",
        "\n",
        "        # skips last target channel if needed\n",
        "        target = target[:, :-1, ...]\n",
        "\n",
        "        if self.squeeze_channel:\n",
        "            # squeeze channel dimension if singleton\n",
        "            target = torch.squeeze(target, dim=1)\n",
        "        return self.loss(input, target)\n",
        "\n",
        "\n",
        "class _AbstractDiceLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Base class for different implementations of Dice loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weight=None, normalization='sigmoid'):\n",
        "        super(_AbstractDiceLoss, self).__init__()\n",
        "        self.register_buffer('weight', weight)\n",
        "        # The output from the network during training is assumed to be un-normalized probabilities and we would\n",
        "        # like to normalize the logits. Since Dice (or soft Dice in this case) is usually used for binary data,\n",
        "        # normalizing the channels with Sigmoid is the default choice even for multi-class segmentation problems.\n",
        "        # However if one would like to apply Softmax in order to get the proper probability distribution from the\n",
        "        # output, just specify `normalization=Softmax`\n",
        "        assert normalization in ['sigmoid', 'softmax', 'none']\n",
        "        if normalization == 'sigmoid':\n",
        "            self.normalization = nn.Sigmoid()\n",
        "        elif normalization == 'softmax':\n",
        "            self.normalization = nn.Softmax(dim=1)\n",
        "        else:\n",
        "            self.normalization = lambda x: x\n",
        "\n",
        "    def dice(self, input, target, weight):\n",
        "        # actual Dice score computation; to be implemented by the subclass\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        # get probabilities from logits\n",
        "        input = self.normalization(input)\n",
        "\n",
        "        # compute per channel Dice coefficient\n",
        "        per_channel_dice = self.dice(input, target, weight=self.weight)\n",
        "\n",
        "        # average Dice score across all channels/classes\n",
        "        return 1. - torch.mean(per_channel_dice)\n",
        "\n",
        "\n",
        "class DiceLoss(_AbstractDiceLoss):\n",
        "    \"\"\"Computes Dice Loss according to https://arxiv.org/abs/1606.04797.\n",
        "    For multi-class segmentation `weight` parameter can be used to assign different weights per class.\n",
        "    The input to the loss function is assumed to be a logit and will be normalized by the Sigmoid function.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weight=None, normalization='sigmoid'):\n",
        "        super().__init__(weight, normalization)\n",
        "\n",
        "    def dice(self, input, target, weight):\n",
        "        return compute_per_channel_dice(input, target, weight=self.weight)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:44.831013Z",
          "iopub.execute_input": "2021-09-01T08:36:44.831443Z",
          "iopub.status.idle": "2021-09-01T08:36:44.844805Z",
          "shell.execute_reply.started": "2021-09-01T08:36:44.831408Z",
          "shell.execute_reply": "2021-09-01T08:36:44.843862Z"
        },
        "trusted": true,
        "id": "04CpkxdozI2m"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# criterion=smp.utils.losses.DiceLoss()\n",
        "criterion = DiceLoss()\n",
        "optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:33:21.707524Z",
          "iopub.execute_input": "2021-09-01T08:33:21.707868Z",
          "iopub.status.idle": "2021-09-01T08:33:21.714728Z",
          "shell.execute_reply.started": "2021-09-01T08:33:21.707835Z",
          "shell.execute_reply": "2021-09-01T08:33:21.713748Z"
        },
        "trusted": true,
        "id": "CM60zs5NzI2n",
        "outputId": "73de6890-e839-49c2-d09b-c6ef20e06338"
      },
      "source": [
        "#base_filter=6\n",
        "sum([param.nelement() for param in model.parameters()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "7124336"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:34:02.511463Z",
          "iopub.execute_input": "2021-09-01T08:34:02.511802Z",
          "iopub.status.idle": "2021-09-01T08:34:02.518590Z",
          "shell.execute_reply.started": "2021-09-01T08:34:02.511755Z",
          "shell.execute_reply": "2021-09-01T08:34:02.517813Z"
        },
        "trusted": true,
        "id": "-LpuFbw_zI2o",
        "outputId": "61391cbd-585e-4d86-de73-0962e13d4fc8"
      },
      "source": [
        "#16\n",
        "sum([param.nelement() for param in model.parameters()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "7124336"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:36:44.846000Z",
          "iopub.execute_input": "2021-09-01T08:36:44.846412Z",
          "iopub.status.idle": "2021-09-01T08:36:44.855751Z",
          "shell.execute_reply.started": "2021-09-01T08:36:44.846375Z",
          "shell.execute_reply": "2021-09-01T08:36:44.854889Z"
        },
        "trusted": true,
        "id": "lrQIeVzWzI2p",
        "outputId": "6fdbef6a-aab6-43d4-e5ab-9e8d2cd2a747"
      },
      "source": [
        "#13\n",
        "sum([param.nelement() for param in model.parameters()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "4703309"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T08:37:47.218027Z",
          "iopub.execute_input": "2021-09-01T08:37:47.218381Z"
        },
        "trusted": true,
        "id": "6dbWs1uBzI2q",
        "colab": {
          "referenced_widgets": [
            "16869b078442423fa015ed314e50d264"
          ]
        },
        "outputId": "a7ff0bce-0117-4228-f923-9bcec866ded9"
      },
      "source": [
        "# number of epochs to train the model\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "n_epochs = 100\n",
        "cnt=0\n",
        "valid_loss_min = np.inf # track change in validation loss\n",
        "\n",
        "# keep track of training and validation loss\n",
        "train_loss = torch.zeros(n_epochs)\n",
        "valid_loss = torch.zeros(n_epochs)\n",
        "\n",
        "model.to(device)\n",
        "for e in range(0, n_epochs):\n",
        "\n",
        "   \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, labels in tqdm(train_loader):\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        data, labels = data.float().to(device), labels.float().to(device) #cpu에 있는 데이터를 gpu에 보냄\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        logits = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(logits, labels)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss[e] += loss.item()\n",
        "        \n",
        "        logits = logits.sigmoid()\n",
        "        logits = logits.detach().cpu()\n",
        "        cnt = cnt+1\n",
        "        \n",
        "        if cnt %200==0:\n",
        "            #1.1.512.512.64\n",
        "            logits=np.transpose(logits.detach().cpu(),(0,4,1,2,3))\n",
        "            labels=np.transpose(labels.detach().cpu(),(0,1,4,2,3))\n",
        "            dataa=np.transpose(data.detach().cpu(),(0,1,4,2,3))\n",
        "            logits = mask_binarization(logits, 0.5)\n",
        "\n",
        "            y=logits[0][15].numpy()\n",
        "            dd=dataa[0][0][15].numpy()\n",
        "            x=labels[0][0][15].numpy()\n",
        "            x1=labels[0][1][15].numpy()\n",
        "\n",
        "            plt.figure(figsize=(16,18))\n",
        "            plt.subplot(1,5,1)\n",
        "            plt.imshow(dd)\n",
        "            plt.subplot(1,5,2)\n",
        "            plt.imshow(x)\n",
        "            plt.subplot(1,5,3)\n",
        "            plt.imshow(x1)\n",
        "            plt.subplot(1,5,4)\n",
        "            plt.imshow(y[0])\n",
        "            plt.subplot(1,5,5)\n",
        "            plt.imshow(y[1])\n",
        "            plt.show()\n",
        "        \n",
        "    train_loss[e] /= len(train_loader)\n",
        "\n",
        "        \n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    with torch.no_grad(): \n",
        "        model.eval()\n",
        "        for data, labels in tqdm(val_loader):\n",
        "            # move tensors to GPU if CUDA is available\n",
        "            data, labels = data.float().to(device), labels.float().to(device)\n",
        "            # forward pass: compute predicted outputs by passing inputs to the model\n",
        "            logits = model(data)\n",
        "            # calculate the batch loss\n",
        "            loss = criterion(logits, labels)\n",
        "            # update average validation loss \n",
        "            valid_loss[e] += loss.item()\n",
        "\n",
        "    \n",
        "    # calculate average losses\n",
        "    valid_loss[e] /= len(val_loader)\n",
        "    scheduler.step(float(valid_loss[e]))\n",
        "    \n",
        "\n",
        "        \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        e, train_loss[e], valid_loss[e]))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss[e] <= valid_loss_min:\n",
        "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss[e]))\n",
        "        torch.save(model.state_dict(), 'model_3d_in1_fixLoss.pt')\n",
        "        valid_loss_min = valid_loss[e]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/160 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16869b078442423fa015ed314e50d264"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T06:53:33.751565Z",
          "iopub.execute_input": "2021-09-01T06:53:33.751884Z",
          "iopub.status.idle": "2021-09-01T06:53:39.781786Z",
          "shell.execute_reply.started": "2021-09-01T06:53:33.751856Z",
          "shell.execute_reply": "2021-09-01T06:53:39.780991Z"
        },
        "trusted": true,
        "id": "pbhaLFBMzI2t"
      },
      "source": [
        "model.load_state_dict(torch.load('../input/bestmodel/model_3d_in1_fixLoss.pt'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T06:53:39.78323Z",
          "iopub.execute_input": "2021-09-01T06:53:39.783566Z",
          "iopub.status.idle": "2021-09-01T06:53:39.7876Z",
          "shell.execute_reply.started": "2021-09-01T06:53:39.783529Z",
          "shell.execute_reply": "2021-09-01T06:53:39.786669Z"
        },
        "trusted": true,
        "id": "Wrxuh135zI2w"
      },
      "source": [
        "os.mkdir('./test_data')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T06:53:39.789321Z",
          "iopub.execute_input": "2021-09-01T06:53:39.789892Z",
          "iopub.status.idle": "2021-09-01T06:53:40.826655Z",
          "shell.execute_reply.started": "2021-09-01T06:53:39.789854Z",
          "shell.execute_reply": "2021-09-01T06:53:40.825813Z"
        },
        "trusted": true,
        "id": "cGXvNyKCzI2x"
      },
      "source": [
        "import glob\n",
        "data_path=sorted(glob.glob( \"../input/body-morphometry-kidney-and-tumor/test/DICOM/**/*.dcm\",recursive=True ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T06:53:48.918941Z",
          "iopub.execute_input": "2021-09-01T06:53:48.919276Z",
          "iopub.status.idle": "2021-09-01T06:54:42.355914Z",
          "shell.execute_reply.started": "2021-09-01T06:53:48.919246Z",
          "shell.execute_reply": "2021-09-01T06:54:42.355097Z"
        },
        "trusted": true,
        "id": "SfbO2FqRzI2y"
      },
      "source": [
        "cnt=0\n",
        "for c in tqdm(range(83)):\n",
        "\n",
        "    input_d=[]\n",
        "    input_p = data_path[cnt:cnt+64]\n",
        "    \n",
        "    for i in range(64):\n",
        "\n",
        "        read = dcm.read_file(input_p[i])\n",
        "        input_d.append(read)\n",
        "    if(c<10):\n",
        "        c=str(c)\n",
        "        c='0'+c\n",
        "    np.save(f'./test_data/{c}', input_d)\n",
        "         \n",
        "    \n",
        "    cnt = cnt+64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T06:54:58.595092Z",
          "iopub.execute_input": "2021-09-01T06:54:58.595435Z",
          "iopub.status.idle": "2021-09-01T06:54:58.600575Z",
          "shell.execute_reply.started": "2021-09-01T06:54:58.595405Z",
          "shell.execute_reply": "2021-09-01T06:54:58.599613Z"
        },
        "trusted": true,
        "id": "Oge13BdjzI2z"
      },
      "source": [
        "import glob\n",
        "path=sorted(glob.glob( \"./test_data/*.npy\",recursive=True ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T05:15:03.572375Z",
          "iopub.execute_input": "2021-09-01T05:15:03.572854Z",
          "iopub.status.idle": "2021-09-01T05:15:03.583056Z",
          "shell.execute_reply.started": "2021-09-01T05:15:03.57282Z",
          "shell.execute_reply": "2021-09-01T05:15:03.582258Z"
        },
        "trusted": true,
        "id": "h5m_gyZBzI3W"
      },
      "source": [
        "len(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T06:55:07.286239Z",
          "iopub.execute_input": "2021-09-01T06:55:07.286575Z",
          "iopub.status.idle": "2021-09-01T06:55:07.292607Z",
          "shell.execute_reply.started": "2021-09-01T06:55:07.286546Z",
          "shell.execute_reply": "2021-09-01T06:55:07.291526Z"
        },
        "trusted": true,
        "id": "dGK7qB9IzI3X"
      },
      "source": [
        "class TestMyDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, x_dir,transform=None):\n",
        "        super().__init__()\n",
        "        self.transform = transform\n",
        "        self.x_img = x_dir\n",
        "     \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x_img)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_img = self.x_img[idx]\n",
        "        # Read an image with OpenCV\n",
        "        x_img = np.load(x_img, allow_pickle=True)\n",
        "        \n",
        "        x_img=read_dicom(x_img,500,0)\n",
        "        x_img=np.transpose(x_img,(2,0,1,3))\n",
        "        \n",
        "       \n",
        "        return x_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T06:55:07.646899Z",
          "iopub.execute_input": "2021-09-01T06:55:07.647225Z",
          "iopub.status.idle": "2021-09-01T06:55:07.652418Z",
          "shell.execute_reply.started": "2021-09-01T06:55:07.647175Z",
          "shell.execute_reply": "2021-09-01T06:55:07.651498Z"
        },
        "trusted": true,
        "id": "YQFD3si7zI3Y"
      },
      "source": [
        "test_dataset=TestMyDataset(path)\n",
        "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-08-31T17:18:21.820131Z",
          "iopub.execute_input": "2021-08-31T17:18:21.820452Z",
          "iopub.status.idle": "2021-08-31T17:18:22.402472Z",
          "shell.execute_reply.started": "2021-08-31T17:18:21.820421Z",
          "shell.execute_reply": "2021-08-31T17:18:22.401459Z"
        },
        "trusted": true,
        "id": "zkcD3r16zI3a"
      },
      "source": [
        "images = next(iter(test_dataloader))\n",
        "print(images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T06:55:22.253577Z",
          "iopub.execute_input": "2021-09-01T06:55:22.253901Z",
          "iopub.status.idle": "2021-09-01T07:11:08.160182Z",
          "shell.execute_reply.started": "2021-09-01T06:55:22.253869Z",
          "shell.execute_reply": "2021-09-01T07:11:08.15882Z"
        },
        "trusted": true,
        "id": "-D-B56uczI3b"
      },
      "source": [
        "#제출양식에 맞지 않음\n",
        "#out channel==2 version\n",
        "def mask_binarization(mask, threshold=None):\n",
        "    if threshold is None:\n",
        "        threshold = 0.5\n",
        "\n",
        "    if isinstance(mask, np.ndarray):\n",
        "        mask_binarized = (mask > threshold).astype(np.uint8)\n",
        "    \n",
        "    elif isinstance(mask, torch.Tensor):\n",
        "        zeros = torch.zeros_like(mask)\n",
        "        ones = torch.ones_like(mask)\n",
        "        \n",
        "        mask_binarized = torch.where(mask > threshold, ones, zeros)\n",
        "    \n",
        "    return mask_binarized\n",
        "\n",
        "def rle_encode(mask_image):\n",
        "    pixels = mask_image.flatten()\n",
        "    pixels[0] = 0\n",
        "    pixels[-1] = 0\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
        "    runs[1::2] = runs[1::2] - runs[:-1:2]\n",
        "    return runs\n",
        "\n",
        "def rle_to_string(runs):\n",
        "    return ' '.join(str(x) for x in runs)\n",
        "\n",
        "\n",
        "preds_string=[]\n",
        "preds = []\n",
        "model.to(device)\n",
        "cnt=0\n",
        "for data in tqdm(test_dataloader):\n",
        "    \n",
        "\n",
        "    data= data.float().to(device)\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    pred = model(data) \n",
        "    \n",
        "    #1.2.512.512.64 -> 64.2.512.512\n",
        "    cnt=cnt+1\n",
        "    if cnt %1==0:\n",
        "            \n",
        "            logits=np.transpose(pred.detach().cpu(),(0,4,1,2,3))\n",
        "            dataa=np.transpose(data.detach().cpu(),(0,1,4,2,3))\n",
        "            logits = mask_binarization(logits, 0.5)\n",
        "\n",
        "            y=logits[0][32].numpy()\n",
        "            dd=dataa[0][0][32].numpy()\n",
        "\n",
        "            plt.figure(figsize=(16,18))\n",
        "            plt.subplot(1,3,1)\n",
        "            plt.imshow(dd)\n",
        "            plt.subplot(1,3,2)\n",
        "            plt.imshow(y[0])\n",
        "            plt.subplot(1,3,3)\n",
        "            plt.imshow(y[1])\n",
        "            plt.show()\n",
        "            \n",
        "    pred = pred.squeeze()\n",
        "    pred = np.transpose(pred.detach().cpu(),(3,0,1,2))\n",
        "    pred = mask_binarization(pred, 0.5)\n",
        "    preds.append(pred)\n",
        "    \n",
        "    for i in range(0, len(preds)):\n",
        "        sample = preds[i] #64.2.512.512\n",
        "        for c in range(2):\n",
        "            for label_code in [1]:\n",
        "                tmp=[]\n",
        "                for s in sample:\n",
        "                    s = np.equal(s[c], label_code).flatten()*1\n",
        "                    tmp+=s.tolist()\n",
        "                enc = rle_to_string(rle_encode(np.array(tmp)))\n",
        "                preds_string.append(enc)\n",
        "    preds=[]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-09-01T07:11:30.630061Z",
          "iopub.execute_input": "2021-09-01T07:11:30.630506Z",
          "iopub.status.idle": "2021-09-01T07:11:30.961471Z",
          "shell.execute_reply.started": "2021-09-01T07:11:30.630463Z",
          "shell.execute_reply": "2021-09-01T07:11:30.960477Z"
        },
        "trusted": true,
        "id": "gJSk-yCUzI3c"
      },
      "source": [
        "sample_submission = pd.read_csv('../input/body-morphometry-kidney-and-tumor/sample_submission.csv')\n",
        "sample_submission['EncodedPixels'] = preds_string\n",
        "sample_submission.to_csv('re_submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}